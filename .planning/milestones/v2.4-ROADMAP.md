# Milestone v2.4: Synthetic.new Integration

**Status:** SHIPPED 2026-02-05
**Phases:** 37-39
**Total Plans:** 7

## Overview

Add Synthetic.new as second LLM provider with 14 new models (reasoning + standard), expanding total from 29 to 36 active models. Goal was to increase model diversity by adding exclusive models not available on Together AI.

## Phases

### Phase 37: Synthetic Provider Foundation

**Goal**: Create SyntheticProvider class and configure 13 models
**Depends on**: None
**Plans**: 3 plans

Plans:

- [x] 37-01: Create SyntheticProvider class extending OpenAICompatibleProvider
- [x] 37-02: Define 13 Synthetic model configurations (4 premium, 9 budget)
- [x] 37-03: Integrate Synthetic providers into registry

**Details:**

Requirements:
- PROV-01: SyntheticProvider class extends OpenAICompatibleProvider
- PROV-02: Provider uses `SYNTHETIC_API_KEY` environment variable
- PROV-03: Provider calls `https://api.synthetic.new/openai/v1/chat/completions`
- PROV-04: Provider handles `hf:org/model` ID format
- MODL-01: 13 Synthetic models defined with ID, name, model, displayName
- MODL-02: Reasoning models marked as premium tier
- MODL-03: Models exported in `SYNTHETIC_PROVIDERS` array
- MODL-04: Provider registry includes Synthetic providers
- ERRH-01: 429 rate limit errors handled with existing retry logic
- ERRH-02: Missing API key throws descriptive error
- ERRH-03: Model failures trigger auto-disable after 3 consecutive failures

Success Criteria:
1. SyntheticProvider class created at `src/lib/llm/providers/synthetic.ts`
2. 13 model configurations defined with correct `hf:` prefixed IDs
3. Provider registry exports combined Together + Synthetic providers
4. API call to Synthetic.new returns valid response
5. Missing API key produces clear error message

---

### Phase 38: Database Integration

**Goal**: Register 13 Synthetic models in database
**Depends on**: Phase 37
**Plans**: 0 plans (auto-implemented by existing architecture)

**Details:**

Requirements:
- DATA-01: Auto-sync registers models via `syncModelsToDatabase()` on server startup
- DATA-02: Models have `provider: 'synthetic'` from `SyntheticProvider.name`
- DATA-03: Models default to `active: true` via sync logic

Implementation Notes:
Phase 38 was already implemented by Phase 37's registry integration. The existing `sync-models.ts` auto-sync mechanism:
- Reads all providers from `getActiveProviders()` (includes SYNTHETIC_PROVIDERS when API key set)
- Upserts each provider into the database with `provider`, `modelName`, `displayName`, `isPremium`, `active: true`
- Runs on server startup — no manual migration or seed script needed

---

### Phase 39: Testing & Validation

**Goal**: Validate working models, disable failing models, add fallback configuration
**Depends on**: Phase 38
**Plans**: 4 plans

Plans:

- [x] 39-01: Create validation script and test all 13 models
- [x] 39-02: Disable 6 failing Synthetic models (gap closure)
- [x] 39-03: Add Together AI fallback mapping (gap closure)
- [x] 39-04: Run production prediction cycle with Synthetic models (gap closure)

**Details:**

Requirements:
- TEST-01: Each model tested with sample prediction
- TEST-02: Thinking model output correctly parsed
- TEST-03: GLM models monitored for Chinese output

Validation Results:
| # | ID | Status | Notes |
|---|-----|--------|-------|
| 1 | deepseek-r1-0528-syn | **Active** | Reasoning, works correctly |
| 2 | kimi-k2-thinking-syn | **Active** | Reasoning, works correctly |
| 3 | qwen3-235b-thinking-syn | Disabled | Parse failure |
| 4 | deepseek-v3-0324-syn | **Active** | Standard, works correctly |
| 5 | deepseek-v3.1-terminus-syn | **Active** | Standard, works correctly |
| 6 | deepseek-v3.2-syn | Disabled | Parse failure |
| 7 | minimax-m2-syn | **Active** | Standard, works correctly |
| 8 | minimax-m2.1-syn | **Active** | Standard, works correctly |
| 9 | kimi-k2.5-syn | Disabled | Timeout |
| 10 | glm-4.6-syn | Disabled | Timeout |
| 11 | glm-4.7-syn | Disabled | API bug (SGLang issue) |
| 12 | qwen3-coder-480b-syn | **Active** | Standard, works correctly |
| 13 | gpt-oss-120b-syn | Disabled | Invalid response |

**Summary:** 7 active, 6 disabled

---

## Milestone Summary

**Key Decisions:**

- Add Synthetic.new alongside Together AI (not replace)
- Keep Together AI models for overlapping models (prefer existing)
- Skip vision model (Qwen3-VL) - not useful for text predictions
- Include GLM models despite Chinese output risk (auto-disabled after validation)
- All Synthetic model IDs use -syn suffix to distinguish from Together
- 13 models configured (4 premium, 9 budget) with placeholder pricing
- Provider registry checks each API key independently (TOGETHER_API_KEY, SYNTHETIC_API_KEY)
- Fallback mapping (deepseek-r1-0528-syn -> deepseek-r1, kimi-k2-thinking-syn -> kimi-k2-instruct)

**Issues Resolved:**

- JSON mode support unknown on Synthetic.new — parser handles non-JSON gracefully
- Model validation script created for future model testing
- Fallback mechanism added for cross-provider resilience

**Issues Deferred:**

- GLM-4.7 has known SGLang structured output bug — blocked until upstream fix
- 2 Synthetic models timeout consistently (kimi-k2.5-syn, glm-4.6-syn) — may need rate limit investigation
- 2 reasoning models return natural language instead of JSON (qwen3-235b-thinking, deepseek-v3.2) — may need prompt adjustment

**Technical Debt Incurred:**

- 6 model definitions preserved in code but not exported (for future re-testing when upstream issues fixed)
- Placeholder pricing for all Synthetic models (no published costs from Synthetic.new)

---

*For current project status, see .planning/ROADMAP.md*

---

*Archived: 2026-02-05 as part of v2.4 milestone completion*
