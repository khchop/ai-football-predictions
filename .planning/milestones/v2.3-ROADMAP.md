# Milestone v2.3: Content Pipeline & SEO

**Status:** âœ… SHIPPED 2026-02-04
**Phases:** 31-36
**Total Plans:** 13

## Overview

This milestone fixes the broken content generation pipeline that left all matches from 2026-02-03 without content, then hardens the pipeline for reliability and optimizes content prompts for SEO/GEO visibility. The journey moves from diagnosis through error handling fixes, HTML sanitization, monitoring infrastructure, prompt optimization, and finally blog generation completion.

## Phases

### Phase 31: Investigation & Diagnosis

**Goal**: Confirm the root cause of missing content and quantify affected matches before making code changes
**Depends on**: Nothing (first phase of v2.3)
**Plans**: 1 plan

Plans:
- [x] 31-01: Run diagnostic queries and document findings in INVESTIGATION.md

**Details:**
- Worker process status verified (not running since 2026-02-01)
- Queue counts and DLQ entries documented
- Count of matches missing content: 5 in last 7 days
- Root cause confirmed: Application server not running, REDIS_URL missing

### Phase 32: Make Failures Visible

**Goal**: Content generation failures are properly thrown and retried by BullMQ
**Depends on**: Phase 31
**Plans**: 2 plans

Plans:
- [x] 32-01: Create error classes and convert return false to throw error
- [x] 32-02: Configure lock duration, DLQ handling, and content validation

**Details:**
- Created RetryableContentError and FatalContentError classes
- Converted all 4 content generation functions from `return false` to `throw`
- Configured 120-second lock duration with 30s heartbeat
- 5 retry attempts with exponential backoff
- Concurrency 3 for content worker
- DLQ retention 7 days

### Phase 33: HTML Sanitization

**Goal**: All LLM-generated content is plain text without HTML artifacts
**Depends on**: Phase 32
**Plans**: 3 plans

Plans:
- [x] 33-01: Create sanitization module and update prompts for plain text
- [x] 33-02: Integrate sanitization before database save
- [x] 33-03: Run migration to clean existing content

**Details:**
- Used html-to-text and he libraries (npm standards)
- Defense-in-depth: prompts request plain text AND runtime sanitization
- Sanitize after LLM response, before validation and database save
- Migration cleaned 341 records across 4 tables

### Phase 34: Pipeline Hardening

**Goal**: Content pipeline has observability and automatic protection against cascading failures
**Depends on**: Phase 33
**Plans**: 2 plans

Plans:
- [x] 34-01: Queue-level circuit breaker for rate limits
- [x] 34-02: Worker health monitoring and content completeness alerts

**Details:**
- In-memory circuit breaker state (no Redis persistence needed)
- 5 consecutive errors, 60s cooldown for rate limit protection
- 5-minute stalled threshold for worker health detection
- Sentry warning level for missing content alerts

### Phase 35: SEO/GEO Content Quality

**Goal**: Content prompts produce answer-first, match-specific content optimized for AI search visibility
**Depends on**: Phase 34
**Plans**: 3 plans

Plans:
- [x] 35-01: Answer-first prompts for pre-match and post-match content
- [x] 35-02: Match-specific FAQ generation with accuracy data
- [x] 35-03: Article schema with datePublished/dateModified

**Details:**
- Answer-first prompts with positive/negative examples
- 30-60 word constraint for opening paragraph
- Entity name consistency rules in prompts
- FAQ #2 mandatory accuracy question for finished matches
- Consensus prediction calculation for upcoming matches
- Use kickoffTime as datePublished, 3-level fallback for dateModified

### Phase 36: Blog Generation

**Goal**: Blog posts generate reliably for eligible matches with proper error handling
**Depends on**: Phase 35
**Plans**: 2 plans

Plans:
- [x] 36-01: Answer-first prompts for blog content (league roundups, model reports)
- [x] 36-02: Error handling alignment and job scheduler verification

**Details:**
- League roundup excerpt: top 3 models + accuracy %
- Model report excerpt: top model + ROI + profitable count
- GOOD/BAD examples with data interpolation in prompts
- Use RetryableContentError for LLM failures in blog generation
- Use FatalContentError for validation failures (no retry for hallucination)

---

## Milestone Summary

**Key Decisions:**
- Investigation before code changes (confirm root cause first)
- Error throwing over return false (BullMQ retry pattern)
- Defense-in-depth for HTML sanitization (prompts + runtime)
- In-memory circuit breaker state (acceptable transient state)
- Answer-first prompts with concrete examples (LLM guidance)

**Issues Resolved:**
- Root cause: Application server not running since 2026-02-01
- Silent failures now throw proper errors with retry/DLQ
- HTML artifacts removed from all content paths
- Rate limit cascading failures prevented by circuit breaker
- Content quality optimized for GEO/AI search visibility

**Issues Deferred:**
- REDIS_URL environment variable configuration (infrastructure concern)
- Validation pattern tuning based on production LLM output

**Technical Debt Incurred:**
None - all implementations complete without stubs or TODOs.

---

_For current project status, see .planning/ROADMAP.md_
