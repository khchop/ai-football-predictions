---
phase: 43-testing-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - vitest.config.ts
  - package.json
  - src/__tests__/setup.ts
  - src/__tests__/fixtures/test-data.ts
  - src/__tests__/schemas/prediction.ts
autonomous: true

must_haves:
  truths:
    - "Vitest test framework is installed and configured"
    - "Test helper utilities are available for integration tests"
    - "Zod validation schema exists for prediction JSON structure"
  artifacts:
    - path: "vitest.config.ts"
      provides: "Vitest configuration with Node environment"
      contains: "testTimeout"
    - path: "src/__tests__/setup.ts"
      provides: "Test setup with environment variable handling"
      contains: "beforeAll"
    - path: "src/__tests__/schemas/prediction.ts"
      provides: "Zod schema for prediction validation"
      exports: ["PredictionOutputSchema", "BatchPredictionSchema"]
  key_links:
    - from: "vitest.config.ts"
      to: "src/__tests__/setup.ts"
      via: "setupFiles configuration"
      pattern: "setupFiles.*setup\\.ts"
---

<objective>
Set up Vitest testing framework and create validation infrastructure for LLM model testing.

Purpose: Establish the foundation for integration testing across all 42 models with proper timeout handling, test fixtures, and Zod-based JSON schema validation.

Output: Working Vitest configuration, test setup files, and reusable Zod schemas for validating prediction JSON structures.
</objective>

<execution_context>
@/Users/pieterbos/.claude/get-shit-done/workflows/execute-plan.md
@/Users/pieterbos/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/43-testing-validation/43-RESEARCH.md
@scripts/validate-synthetic-models.ts
@src/lib/llm/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Vitest and configure test framework</name>
  <files>
    - package.json
    - vitest.config.ts
    - src/__tests__/setup.ts
  </files>
  <action>
1. Install test dependencies:
   ```bash
   npm install --save-dev vitest @vitest/ui
   ```

2. Create `vitest.config.ts` in project root:
   - Set environment to 'node' (not jsdom - we're testing APIs)
   - Set testTimeout to 60000 (60s default for LLM APIs)
   - Set hookTimeout to 10000
   - Set maxConcurrency to 5 (avoid rate limits)
   - Configure path aliases to match tsconfig (@ -> ./src)
   - Include pattern: `src/__tests__/**/*.test.ts`
   - Exclude: node_modules, .next, dist

3. Create `src/__tests__/setup.ts`:
   - Load dotenv from .env.local for API keys
   - Export `TEST_MODE` constant (reads from process.env.TEST_MODE)
   - Export `shouldSkipRealAPI` helper (returns true if no API keys)
   - Log test configuration at startup (which APIs available)

4. Add test scripts to package.json:
   - "test": "vitest run"
   - "test:watch": "vitest"
   - "test:ui": "vitest --ui"

Do NOT install MSW yet - we'll use real APIs for validation runs.
  </action>
  <verify>
Run `npm run test` (should pass with no tests found, no errors).
Run `npx vitest --version` to confirm installation.
  </verify>
  <done>
Vitest installed and configured. Running `npm run test` shows "no tests found" but no configuration errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create test fixtures and Zod validation schemas</name>
  <files>
    - src/__tests__/fixtures/test-data.ts
    - src/__tests__/schemas/prediction.ts
  </files>
  <action>
1. Create `src/__tests__/fixtures/test-data.ts`:
   - Export TEST_MATCH_ID = 'test-validation-001'
   - Export TEST_PROMPT based on existing validate-synthetic-models.ts format:
     ```typescript
     export const TEST_PROMPT = `Provide a prediction for 1 test match.
     Match ID: ${TEST_MATCH_ID}
     Home Team: Manchester United
     Away Team: Liverpool
     Competition: Premier League
     Kickoff: 2026-02-10

     Respond with JSON array containing match_id, home_score, away_score.`;
     ```
   - Export timeout constants:
     - REASONING_MODEL_TIMEOUT = 90000 (90s for deepseek-r1, kimi-thinking, qwen3-thinking)
     - STANDARD_MODEL_TIMEOUT = 60000 (60s default)
     - JSON_STRICT_TIMEOUT = 45000 (45s for JSON-strict models)
   - Export REASONING_MODEL_IDS set: ['deepseek-r1-0528-syn', 'kimi-k2-thinking-syn', 'qwen3-235b-thinking-syn', 'deepseek-r1']

2. Create `src/__tests__/schemas/prediction.ts`:
   - Import z from 'zod' (already in project)
   - Export PredictionOutputSchema:
     ```typescript
     export const PredictionOutputSchema = z.object({
       match_id: z.string(),
       home_score: z.number().int().min(0).max(20),
       away_score: z.number().int().min(0).max(20),
     });
     ```
   - Export BatchPredictionSchema (array of predictions)
   - Export type aliases: PredictionOutput, BatchPrediction
   - Export validatePrediction helper function that returns { success, data?, errors? }

The Zod schema validates JSON STRUCTURE, not exact values (LLM outputs are non-deterministic).
  </action>
  <verify>
TypeScript compiles: `npx tsc --noEmit src/__tests__/schemas/prediction.ts`
Import check: Create a minimal test file that imports the schema and run `npm run test`.
  </verify>
  <done>
Test fixtures and Zod schemas created. Schemas can be imported and used for validation.
  </done>
</task>

</tasks>

<verification>
1. `npm run test` executes without errors
2. `cat vitest.config.ts` shows Node environment and 60s timeout
3. `cat src/__tests__/schemas/prediction.ts` exports PredictionOutputSchema
4. TypeScript compilation passes with no errors
</verification>

<success_criteria>
- Vitest installed and configured in package.json
- vitest.config.ts present with correct settings (node env, 60s timeout, max concurrency 5)
- Test setup file loads environment variables
- Zod schemas validate prediction structure (not values)
- `npm run test` runs without configuration errors
</success_criteria>

<output>
After completion, create `.planning/phases/43-testing-validation/43-01-SUMMARY.md`
</output>
