---
phase: 39-testing-validation
plan: 03
type: execute
wave: 2
depends_on:
  - 39-02
files_modified:
  - src/lib/llm/providers/together.ts
  - src/lib/llm/index.ts
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Fallback model mapping exists and is exported for future integration"
    - "Model equivalence mapping documented for overlapping models"
    - "Fallback lookup function available for prediction pipeline"
  artifacts:
    - path: "src/lib/llm/index.ts"
      provides: "Fallback model mapping and lookup function"
      exports: ["getFallbackProvider", "MODEL_FALLBACKS"]
  key_links:
    - from: "src/lib/llm/index.ts"
      to: "src/lib/llm/providers/together.ts"
      via: "TOGETHER_PROVIDERS import"
      pattern: "import.*TOGETHER_PROVIDERS"
---

<objective>
Add Together AI as fallback for Synthetic models that share the same underlying model. Create a mapping of Synthetic model IDs to equivalent Together AI model IDs for future fallback use.

Purpose: Increase prediction success rate by having backup providers for overlapping models
Output: Model fallback mapping and lookup function in src/lib/llm/index.ts
</objective>

<execution_context>
@/Users/pieterbos/.claude/get-shit-done/workflows/execute-plan.md
@/Users/pieterbos/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/39-testing-validation/39-01-SUMMARY.md

@src/lib/llm/providers/together.ts
@src/lib/llm/providers/synthetic.ts
@src/lib/llm/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create model fallback mapping</name>
  <files>src/lib/llm/index.ts</files>
  <action>
Add a fallback mapping from Synthetic model IDs to Together AI model IDs for overlapping models.

1. **Identify overlapping models** (same underlying model, different providers):

   | Synthetic ID | Together ID | Notes |
   |--------------|-------------|-------|
   | deepseek-r1-0528-syn | deepseek-r1 | Both use DeepSeek R1 (different versions) |
   | kimi-k2-thinking-syn | kimi-k2-instruct | Thinking vs Instruct version |
   | qwen3-235b-thinking-syn (disabled) | qwen3-235b-instruct | Thinking vs Instruct |

   Note: Most Synthetic models are exclusive (no Together equivalent).

2. **Add fallback mapping after ALL_PROVIDERS:**

   ```typescript
   // ============================================================================
   // MODEL FALLBACKS
   // Maps Synthetic model IDs to Together AI equivalents (same or similar models)
   // Used when a Synthetic model fails and we want to try Together AI instead
   // ============================================================================

   /**
    * Fallback mapping: Synthetic model ID -> Together AI model ID
    * Only includes models with close equivalents on both providers
    */
   export const MODEL_FALLBACKS: Record<string, string> = {
     // DeepSeek R1 variants (reasoning models)
     'deepseek-r1-0528-syn': 'deepseek-r1',

     // Kimi K2 variants (Thinking -> Instruct fallback)
     'kimi-k2-thinking-syn': 'kimi-k2-instruct',

     // Qwen3 235B variants (Thinking -> Instruct fallback, both are disabled/premium)
     // 'qwen3-235b-thinking-syn': 'qwen3-235b-instruct',  // Synthetic version disabled

     // Note: Most Synthetic models are exclusive (MiniMax, GLM, DeepSeek V3 variants)
     // and have no Together AI equivalent
   };

   /**
    * Get fallback provider for a Synthetic model
    * @param syntheticModelId - The Synthetic model ID that failed
    * @returns The equivalent Together AI provider, or undefined if no fallback exists
    */
   export function getFallbackProvider(syntheticModelId: string): LLMProvider | undefined {
     const fallbackId = MODEL_FALLBACKS[syntheticModelId];
     if (!fallbackId) {
       return undefined;
     }

     // Check if Together API key is configured
     if (!process.env.TOGETHER_API_KEY) {
       return undefined;
     }

     return ALL_PROVIDERS.find(p => p.id === fallbackId);
   }
   ```

3. **Add to existing exports at the end of the file:**

   ```typescript
   // Export fallback utilities
   export { MODEL_FALLBACKS, getFallbackProvider };
   ```

**Implementation notes:**
- The mapping is intentionally conservative - only truly equivalent models
- Kimi K2 Thinking -> K2 Instruct is a reasonable fallback (same base model)
- DeepSeek R1 0528 -> R1 is close (version difference)
- Don't map disabled models (they're disabled for a reason)
- Don't force fallbacks for models with no good equivalent

**WHY this approach:**
- Simple lookup table, no complex logic
- Fallback is opt-in (prediction pipeline decides when to use it)
- Easy to extend as more models become available
- Doesn't change existing prediction flow (future integration)
  </action>
  <verify>
1. TypeScript compiles: `npx tsc --noEmit`
2. Exports exist:
   ```bash
   grep -E "export.*MODEL_FALLBACKS|export.*getFallbackProvider" src/lib/llm/index.ts
   ```
3. Mapping is correct:
   ```bash
   grep -A 10 "MODEL_FALLBACKS:" src/lib/llm/index.ts
   ```
  </verify>
  <done>
- MODEL_FALLBACKS mapping added to src/lib/llm/index.ts
- getFallbackProvider function implemented
- TypeScript compiles without errors
- Exports are available for prediction pipeline use
  </done>
</task>

<task type="auto">
  <name>Task 2: Document fallback strategy for future use</name>
  <files></files>
  <action>
The fallback mapping is now available but NOT yet integrated into the prediction pipeline.

**Current state:**
- MODEL_FALLBACKS maps 2 Synthetic models to Together equivalents
- getFallbackProvider() returns the fallback provider if available
- Prediction pipeline does NOT automatically use fallbacks (intentional)

**Future integration points** (NOT implemented in this plan):

1. **In predictions.worker.ts (batch predictions):**
   ```typescript
   // After a Synthetic model fails
   const fallback = getFallbackProvider(provider.id);
   if (fallback) {
     logger.info({ original: provider.id, fallback: fallback.id }, 'Trying fallback provider');
     result = await fallback.predictBatch(prompt, matchIds);
   }
   ```

2. **In auto-disable flow:**
   - When a model is auto-disabled, could automatically try fallback
   - Adds complexity - defer to future enhancement

**Document in code comment** at end of MODEL_FALLBACKS section:

```typescript
// ============================================================================
// USAGE NOTES:
// - Call getFallbackProvider(modelId) when a Synthetic model fails
// - Returns undefined if no fallback exists or TOGETHER_API_KEY not set
// - Integration into prediction pipeline is a future enhancement
// - Currently 2 fallbacks configured (deepseek-r1, kimi-k2)
// ============================================================================
```

This task is primarily documentation - the mapping exists, integration is separate work.
  </action>
  <verify>
1. Usage notes comment exists in code
2. getFallbackProvider returns correct providers when called:
   ```typescript
   // Manual test in REPL or unit test
   getFallbackProvider('deepseek-r1-0528-syn')?.id === 'deepseek-r1'
   getFallbackProvider('unknown-model') === undefined
   ```
  </verify>
  <done>
- Fallback mapping implemented and exported
- Usage documented in code comments
- Ready for future integration into prediction pipeline
- No changes to prediction flow (intentional - separate enhancement)
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes
2. MODEL_FALLBACKS exported from src/lib/llm/index.ts
3. getFallbackProvider function works correctly
4. Mapping includes deepseek-r1 and kimi-k2 fallbacks
5. Documentation notes present for future integration
</verification>

<success_criteria>
1. MODEL_FALLBACKS constant created with 2 fallback mappings
2. getFallbackProvider function returns correct providers
3. Both exports available from src/lib/llm/index.ts
4. TypeScript compiles without errors
5. Usage notes document how to integrate in future
</success_criteria>

<output>
After completion, create `.planning/phases/39-testing-validation/39-03-SUMMARY.md`
</output>
