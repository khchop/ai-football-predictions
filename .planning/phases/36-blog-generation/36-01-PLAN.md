---
phase: 36-blog-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/content/prompts.ts
autonomous: true

must_haves:
  truths:
    - "League roundup prompts request answer-first structure in opening 30-60 words"
    - "Model report prompts request answer-first structure in opening 30-60 words"
    - "Prompts include positive and negative examples for answer-first pattern"
  artifacts:
    - path: "src/lib/content/prompts.ts"
      provides: "Answer-first prompt templates for blog content"
      contains: "Opening Summary (30-60 words)"
  key_links:
    - from: "src/lib/content/prompts.ts"
      to: "src/lib/content/generator.ts"
      via: "buildLeagueRoundupPrompt, buildModelReportPrompt"
      pattern: "buildLeagueRoundupPrompt|buildModelReportPrompt"
---

<objective>
Update blog content prompts to use answer-first structure for GEO optimization

Purpose: Blog posts should follow the same answer-first pattern established in Phase 35 for match content. This structure leads to 3.4x more AI citations by placing the key information in the first 30-60 words.

Output: Modified `buildLeagueRoundupPrompt` and `buildModelReportPrompt` functions with answer-first instructions and examples
</objective>

<execution_context>
@/Users/pieterbos/.claude/get-shit-done/workflows/execute-plan.md
@/Users/pieterbos/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/36-blog-generation/36-RESEARCH.md
@src/lib/content/prompts.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update buildLeagueRoundupPrompt with answer-first structure</name>
  <files>src/lib/content/prompts.ts</files>
  <action>
Modify the `buildLeagueRoundupPrompt` function to add answer-first structure instructions. Update the OUTPUT REQUIREMENTS section to include:

1. Add a new section for "Opening Summary (CRITICAL - Answer-First Structure)" before the existing content sections:

```typescript
## OUTPUT REQUIREMENTS

### Opening Summary (CRITICAL - Answer-First Structure)
Start the excerpt AND the content with a 30-60 word paragraph that directly answers:
1. Which models performed best this week (name top 3 with avg points/match)
2. Overall accuracy rate (X% correct tendency)
3. Biggest surprise or upset result

GOOD EXAMPLE:
"Llama 3.3 70B led ${competition} predictions this week with 4.2 points per match, followed by GPT-4 Turbo (3.8) and Claude Opus (3.6). Models achieved 67% correct tendency overall, though the [biggest upset] caught most models off guard."

BAD EXAMPLE (DO NOT USE):
"This week saw exciting ${competition} action with several unexpected results. In this analysis, we'll examine AI model performance across all matches and dive into the key factors that influenced accuracy rates this round."

### Full Content Structure
After the opening summary, provide:
- ## Top 10 Models (table with avg points/match ranking)
- ## Match-by-Match Audit (each match with accuracy stats)
- ## Biggest Consensus Misses (upsets that fooled most models)
- ## Methodology (how scoring works)
```

2. Update the JSON schema description for "excerpt" field:
```typescript
"excerpt": "Opening summary (30-60 words, answer-first with top 3 models and accuracy %)",
```

3. Update the JSON schema description for "content" field to mention repeating the opening summary:
```typescript
"content": "Markdown. Start with opening summary (same as excerpt), then: ## Top 10 Models, ## Match-by-Match Audit, ## Biggest Consensus Misses, ## Methodology",
```

Keep all existing RULES and DATA sections unchanged. Only modify the OUTPUT REQUIREMENTS section.
  </action>
  <verify>
Read the modified `buildLeagueRoundupPrompt` function and confirm:
- Contains "Opening Summary (CRITICAL - Answer-First Structure)" section
- Contains GOOD EXAMPLE and BAD EXAMPLE
- excerpt field description mentions "30-60 words, answer-first"
- content field description mentions "Start with opening summary"
  </verify>
  <done>
buildLeagueRoundupPrompt includes answer-first instructions with concrete examples, excerpt specifies 30-60 word answer-first structure
  </done>
</task>

<task type="auto">
  <name>Task 2: Update buildModelReportPrompt with answer-first structure</name>
  <files>src/lib/content/prompts.ts</files>
  <action>
Modify the `buildModelReportPrompt` function to add answer-first structure. The current prompt has a generic "Executive Summary" section. Update it to enforce answer-first:

1. Replace the existing section 1 with explicit answer-first instructions:

```typescript
Write a comprehensive AI model performance report with:

1. **Opening Summary (CRITICAL - Answer-First)**
   First 30-60 words MUST directly answer: Which model won? What was their ROI? How many models were profitable?

   GOOD EXAMPLE:
   "${topModels[0]?.name || 'Top model'} dominated ${period} with ${topModels[0]?.roi?.toFixed(1) || 'N/A'}% ROI, significantly outperforming the field average of ${overallStats.averageROI.toFixed(1)}%. ${topModels.filter(m => m.roi > 0).length} of ${topModels.length} tracked models finished profitable this period."

   BAD EXAMPLE (DO NOT USE):
   "This comprehensive report examines the performance of AI betting models during ${period}. We'll analyze various metrics including ROI, win rate, and betting patterns to understand what drove success."

2. **Detailed Model Analysis** (400-500 words)
   - Break down each top model's strategy
   - What makes the winners successful
   - Notable patterns and insights

3. **Market Insights** (200-250 words)
   - Which types of bets performed best
   - Competition difficulty analysis
   - ROI trends over the period

4. **Looking Forward** (150-200 words)
   - Predictions for next period
   - Models to watch
   - Market opportunities
```

2. Update the JSON schema for "excerpt":
```typescript
"excerpt": "Opening summary (30-60 words, answer-first: top model name + ROI + profitable count)",
```

Keep all other instructions (Writing Guidelines, Return format) unchanged.
  </action>
  <verify>
Read the modified `buildModelReportPrompt` function and confirm:
- Section 1 is now "Opening Summary (CRITICAL - Answer-First)"
- Contains GOOD EXAMPLE and BAD EXAMPLE with actual data interpolation
- excerpt field description specifies "30-60 words, answer-first"
  </verify>
  <done>
buildModelReportPrompt includes answer-first instructions with concrete examples using actual model data, excerpt specifies 30-60 word answer-first structure
  </done>
</task>

</tasks>

<verification>
After both tasks complete:
1. Run TypeScript compilation: `npx tsc --noEmit` - should pass without errors
2. Verify prompts.ts exports unchanged: `grep "export function build" src/lib/content/prompts.ts` - should show same function names
3. Verify answer-first pattern present in both prompts: `grep -A 3 "Answer-First" src/lib/content/prompts.ts` - should show both functions have the pattern
</verification>

<success_criteria>
1. buildLeagueRoundupPrompt includes "Opening Summary (CRITICAL - Answer-First Structure)" with GOOD/BAD examples
2. buildModelReportPrompt includes "Opening Summary (CRITICAL - Answer-First)" with GOOD/BAD examples
3. Both functions compile without TypeScript errors
4. Excerpt fields in JSON schema specify 30-60 word answer-first structure
</success_criteria>

<output>
After completion, create `.planning/phases/36-blog-generation/36-01-SUMMARY.md`
</output>
