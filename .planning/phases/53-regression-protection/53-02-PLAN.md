---
phase: 53-regression-protection
plan: 02
type: execute
wave: 2
depends_on: ["53-01"]
files_modified:
  - src/lib/validation/prediction-schema.ts
  - src/lib/queue/workers/predictions.worker.ts
  - src/__tests__/schemas/prediction.ts
  - .github/workflows/regression-tests.yml
autonomous: true

must_haves:
  truths:
    - "predictions.worker.ts validates each prediction with Zod safeParse before database insert"
    - "Invalid predictions (non-integer scores, missing fields, scores >20) are skipped with error logging"
    - "Model failures from schema validation are recorded via recordModelFailure()"
    - "Pull requests changing src/lib/llm/** trigger automated regression tests in CI"
    - "CI test failure blocks PR merge"
  artifacts:
    - path: "src/lib/validation/prediction-schema.ts"
      provides: "Production Zod schema for prediction validation"
      exports: ["PredictionInsertSchema"]
    - path: "src/lib/queue/workers/predictions.worker.ts"
      provides: "Updated worker with Zod validation before database insert"
      contains: "safeParse"
    - path: ".github/workflows/regression-tests.yml"
      provides: "CI workflow running regression tests on LLM config changes"
  key_links:
    - from: "src/lib/queue/workers/predictions.worker.ts"
      to: "src/lib/validation/prediction-schema.ts"
      via: "import PredictionInsertSchema"
      pattern: "import.*prediction-schema"
    - from: ".github/workflows/regression-tests.yml"
      to: "package.json"
      via: "npm run test:regression"
      pattern: "test:regression"
---

<objective>
Add runtime Zod schema validation to the predictions worker (database boundary guard) and create a GitHub Actions CI workflow that automatically runs regression tests on pull requests changing LLM configuration.

Purpose: REGR-02 (schema validation prevents invalid data in database) and REGR-03 (CI automation catches regressions before merge). Together with Plan 53-01, this completes the regression protection safety net for all subsequent model config changes.
Output: Production validation schema, updated predictions worker, GitHub Actions workflow.
</objective>

<execution_context>
@/Users/pieterbos/.claude/get-shit-done/workflows/execute-plan.md
@/Users/pieterbos/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/53-regression-protection/53-RESEARCH.md
@.planning/phases/53-regression-protection/53-01-SUMMARY.md

@src/lib/queue/workers/predictions.worker.ts
@src/__tests__/schemas/prediction.ts
@src/lib/db/schema.ts
@vitest.config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create production Zod schema and add validation to predictions worker</name>
  <files>
    src/lib/validation/prediction-schema.ts
    src/lib/queue/workers/predictions.worker.ts
    src/__tests__/schemas/prediction.ts
  </files>
  <action>
    **Create production validation schema (`src/lib/validation/prediction-schema.ts`):**

    Create a Zod schema specifically for validating prediction data before database insertion:

    ```typescript
    import { z } from 'zod';

    /**
     * Schema for validating a single prediction before database insert.
     * Guards the database boundary — invalid predictions are rejected here.
     *
     * Validates:
     * - predictedHome: integer between 0 and 20 (football scores)
     * - predictedAway: integer between 0 and 20 (football scores)
     * - matchId: non-empty string
     * - modelId: non-empty string
     */
    export const PredictionInsertSchema = z.object({
      predictedHome: z.number().int().min(0).max(20),
      predictedAway: z.number().int().min(0).max(20),
      matchId: z.string().min(1),
      modelId: z.string().min(1),
    });

    export type PredictionInsertInput = z.infer<typeof PredictionInsertSchema>;
    ```

    This is intentionally separate from the test schema (`PredictionOutputSchema`) because:
    - Test schema validates LLM output format (match_id, home_score, away_score)
    - Production schema validates database insert format (matchId, predictedHome, predictedAway)
    - Different field names reflect different stages of the pipeline

    **Update predictions worker (`src/lib/queue/workers/predictions.worker.ts`):**

    Add Zod validation BEFORE `predictionsToInsert.push()` (around line 242):

    1. Import `PredictionInsertSchema` from `@/lib/validation/prediction-schema`
    2. After parsing the prediction response (line 236: `const prediction = parsed.predictions[0]`), add:

    ```typescript
    // Validate prediction structure before database insert (REGR-02)
    const insertValidation = PredictionInsertSchema.safeParse({
      predictedHome: prediction.homeScore,
      predictedAway: prediction.awayScore,
      matchId,
      modelId: provider.id,
    });

    if (!insertValidation.success) {
      log.error({
        modelId: provider.id,
        matchId,
        issues: insertValidation.error.issues,
        rawValues: { home: prediction.homeScore, away: prediction.awayScore },
      }, 'Prediction failed schema validation before database insert');
      await recordModelFailure(provider.id, 'schema_validation_failed', ErrorType.PARSE_ERROR);
      failCount++;
      continue;
    }
    ```

    3. Place this validation BETWEEN the `parseBatchPredictionResponse` success check and the `predictionsToInsert.push()` call
    4. On validation failure: log error with Zod issues, call `recordModelFailure()` with `schema_validation_failed` reason, increment failCount, continue to next model
    5. Do NOT change the data flow for valid predictions — `predictionsToInsert.push()` continues to use the same values

    **Update test schemas (`src/__tests__/schemas/prediction.ts`):**

    Add a comment at the top noting the production schema location, and optionally re-export it:
    ```typescript
    // Production schema for database boundary validation:
    // See src/lib/validation/prediction-schema.ts (PredictionInsertSchema)
    //
    // This file contains TEST schemas for validating LLM output format.
    // The field names differ: LLM output uses match_id/home_score/away_score,
    // while database insert uses matchId/predictedHome/predictedAway.
    ```
    No functional changes — just documentation to prevent confusion about which schema to use where.
  </action>
  <verify>
    - `grep -n "safeParse" src/lib/queue/workers/predictions.worker.ts` shows validation code
    - `grep -n "PredictionInsertSchema" src/lib/validation/prediction-schema.ts` shows schema definition
    - `npm run build` succeeds (or `npx tsc --noEmit` to verify types)
    - The existing schema tests still pass: `npx vitest run src/__tests__/schemas/prediction.test.ts`
  </verify>
  <done>
    Production Zod schema exists at `src/lib/validation/prediction-schema.ts`. Predictions worker validates every prediction with `safeParse()` before database insert. Invalid predictions are logged, recorded as model failures, and skipped (not inserted). Existing tests unaffected.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create GitHub Actions CI workflow for regression tests</name>
  <files>
    .github/workflows/regression-tests.yml
  </files>
  <action>
    Create `.github/workflows/regression-tests.yml`:

    ```yaml
    name: Regression Tests

    on:
      pull_request:
        paths:
          - 'src/lib/llm/**'
          - 'src/lib/queue/workers/predictions.worker.ts'
          - 'src/lib/validation/**'
          - 'src/__tests__/**'
          - 'vitest.config.ts'

    jobs:
      regression:
        name: Model Regression Tests
        runs-on: ubuntu-latest
        timeout-minutes: 5

        steps:
          - name: Checkout code
            uses: actions/checkout@v4

          - name: Setup Node.js
            uses: actions/setup-node@v4
            with:
              node-version: '20'
              cache: 'npm'

          - name: Install dependencies
            run: npm ci

          - name: Run regression tests (offline)
            run: npm run test:regression

          - name: Run schema validation tests
            run: npx vitest run src/__tests__/schemas/
    ```

    **Design decisions:**
    - `timeout-minutes: 5` — offline tests are fast (no API calls), 5 minutes is generous
    - Triggers on changes to LLM code, worker, validation, tests, and vitest config
    - Does NOT use API keys (runs offline fixture tests from 53-01)
    - Runs both regression tests AND schema validation tests
    - No artifact upload needed for offline tests (failures are in test output)
    - The `test:regression:live` script (actual API calls) is intentionally NOT in CI — it's for manual validation only

    **Note about branch protection:**
    After merging, the repository owner should configure branch protection rules in GitHub:
    - Settings > Branches > Add rule for `main`
    - Enable "Require status checks to pass before merging"
    - Add "Model Regression Tests" as required check
    This is a manual GitHub UI step and cannot be automated via CLI without admin access.
  </action>
  <verify>
    - `cat .github/workflows/regression-tests.yml` shows valid YAML
    - Workflow triggers on the correct path patterns
    - Workflow runs `npm run test:regression` (not the live variant)
    - Timeout is set to 5 minutes
    - No secrets are referenced (offline tests don't need API keys)
  </verify>
  <done>
    GitHub Actions workflow exists at `.github/workflows/regression-tests.yml`. It triggers on PRs changing LLM config, validation, or test files. Runs offline regression tests (no API keys needed). Workflow completes in under 2 minutes for fast feedback.
  </done>
</task>

</tasks>

<verification>
1. `grep "safeParse" src/lib/queue/workers/predictions.worker.ts` shows Zod validation
2. `cat src/lib/validation/prediction-schema.ts` shows PredictionInsertSchema
3. `cat .github/workflows/regression-tests.yml` shows valid CI workflow
4. `npm run build` succeeds (no type errors from new imports)
5. `npm run test:regression` still passes after worker changes
6. `npx vitest run src/__tests__/schemas/prediction.test.ts` still passes
</verification>

<success_criteria>
- Every prediction passes through Zod safeParse before database insert
- Invalid predictions are skipped (not inserted) with error logging
- CI workflow triggers on LLM config changes in pull requests
- CI runs offline tests (fast, no API keys needed)
- Existing tests and build remain green
</success_criteria>

<output>
After completion, create `.planning/phases/53-regression-protection/53-02-SUMMARY.md`
</output>
